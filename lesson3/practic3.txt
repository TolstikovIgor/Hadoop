Для запуска задачи MapReduce нужно выполнить команду
yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar pi 32 10000
Также можно изучить различные демо-задачи, которые поставляются в пакете
hadoop-mapreduce-examples.jar
Для отслеживания задания в yarn нужно зайти на страницу по адресу http://185.241.193.174:8088/.
Нужно найти задачу под своим пользователем и проверить статус выполнения.
Работа задачи MapReduce на популярном примере подсчета повторения слов в файле. Для
выполнение, нужно подготовить входные данные. Загрузить любой файл с помощью команды scp с
локального компьютера или скачать с помощью команды wget. Далее нужно создать отдельную папку
в hdfs, используя команду mkdir:
hdfs dfs -mkdir input
Затем загрузить фаил в hdfs-папку с помощью -put
hdfs dfs -put test.txt input/.
В локальной папке сервера, на котором будет запускаться MapReduce нужно создать два файла
mapper.py и reducer.py.
Код в mapper.py и reducer.py написан для выполнения с python3. Нужно помнить об этом и если в
системе стоит отличная версия python, то точно указывать с каким интерпретатором запускать.
Локальное тестирования вычисления производится следующей командой:
cat test.txt | python mapper.py | sort | python reducer.py
Для запуска распределенного вычисления нужно воспользоваться следующей командой:
yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar -input test -output result
-mapper "python mapper.py" -reducer "python reducer.py" -file mapper.py -file reducer.py
Обзор результата
hdfs dfs -cat result/*
Для повторного запуска нужно не забыть удалить старый результат командой:
hdfs dfs -rm -r result
